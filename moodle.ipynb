{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('editing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>...</th>\n",
       "      <th>market_segment_type_0</th>\n",
       "      <th>market_segment_type_1</th>\n",
       "      <th>market_segment_type_2</th>\n",
       "      <th>market_segment_type_3</th>\n",
       "      <th>market_segment_type_4</th>\n",
       "      <th>has_children</th>\n",
       "      <th>co1</th>\n",
       "      <th>co2</th>\n",
       "      <th>co3</th>\n",
       "      <th>co4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>349</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_of_adults  no_of_children  no_of_weekend_nights  no_of_week_nights  \\\n",
       "0             2               0                     1                  4   \n",
       "1             2               1                     0                  2   \n",
       "2             1               0                     1                  5   \n",
       "3             1               0                     2                  4   \n",
       "4             2               0                     0                  4   \n",
       "\n",
       "   required_car_parking_space  lead_time  arrival_year  arrival_month  \\\n",
       "0                           0        118          2017             12   \n",
       "1                           0         17          2018              4   \n",
       "2                           0        349          2018             10   \n",
       "3                           0         69          2018              6   \n",
       "4                           0         11          2018              1   \n",
       "\n",
       "   arrival_date  repeated_guest  ...  market_segment_type_0  \\\n",
       "0            28               0  ...                      0   \n",
       "1            14               0  ...                      0   \n",
       "2             4               0  ...                      1   \n",
       "3            12               0  ...                      1   \n",
       "4            20               0  ...                      0   \n",
       "\n",
       "   market_segment_type_1  market_segment_type_2  market_segment_type_3  \\\n",
       "0                      1                      0                      0   \n",
       "1                      1                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      1                      0                      0   \n",
       "\n",
       "   market_segment_type_4  has_children  co1  co2  co3  co4  \n",
       "0                      0             0    0    0    0    1  \n",
       "1                      0             1    0    1    0    0  \n",
       "2                      0             0    0    0    0    1  \n",
       "3                      0             0    0    1    0    0  \n",
       "4                      0             0    1    0    0    0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10519,) (3507,)\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'booking_status' column from the DataFrame to create the features DataFrame X\n",
    "X = df.drop(columns=['booking_status'])\n",
    "\n",
    "# Select the 'booking_status' column from the DataFrame to create the target Series y\n",
    "y = df['booking_status']\n",
    "\n",
    "# Split the data into training and testing sets, with 25% of the data used for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Print the shapes of the y_train and y_test arrays to verify the split\n",
    "print(y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of canceled bookings in the training set: 0.2905219127293469\n",
      "Percentage of canceled bookings in the testing set: 0.2968349016253208\n"
     ]
    }
   ],
   "source": [
    "# Count the number of canceled bookings in the training set and calculate the percentage\n",
    "NOcanceled = y_train.sum()\n",
    "total = y_train.shape[0]\n",
    "print('Percentage of canceled bookings in the training set:', NOcanceled / total)\n",
    "\n",
    "# Count the number of canceled bookings in the testing set and calculate the percentage\n",
    "NOcanceled = y_test.sum()\n",
    "total = y_test.shape[0]\n",
    "print('Percentage of canceled bookings in the testing set:', NOcanceled / total)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have outlliers in our data set but we think it is acceptable because there some event the price of hotel ancreased and You must book very early before you arrive Although we well tray modeling in both data with outlier and without it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Outliers\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies of the X_train and y_train arrays\n",
    "X_trainOut = X_train.copy()\n",
    "y_trainOut = y_train.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10519, 35) (9770, 35) (10519,) (9770,)\n"
     ]
    }
   ],
   "source": [
    "# Define a function to remove outliers from a dataset based on a specified column\n",
    "def remove_outliers(x, y, column):\n",
    "    # Calculate the first and third quartiles and the interquartile range (IQR)\n",
    "    Q1 = x[column].quantile(0.25)\n",
    "    Q3 = x[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Calculate the lower and upper bounds for outliers using the IQR\n",
    "    lower_bound = Q1 - 1.5*IQR\n",
    "    upper_bound = Q3 + 1.5*IQR\n",
    "    \n",
    "    # Filter the input data (x and y) to remove outliers based on the specified column\n",
    "    y = y[(x[column] >= lower_bound) & (x[column] <= upper_bound)]\n",
    "    x = x[(x[column] >= lower_bound) & (x[column] <= upper_bound)]\n",
    "    \n",
    "    # Return the filtered data\n",
    "    return x, y\n",
    "\n",
    "# Loop through specified columns and remove outliers from the training data\n",
    "for col in ['lead_time', 'avg_price_per_room']:\n",
    "    X_trainOut, y_trainOut = remove_outliers(X_trainOut, y_trainOut, col)\n",
    "\n",
    "# Print the shape of the original and filtered training data, as well as the shape of the original and filtered labels\n",
    "print(X_train.shape, X_trainOut.shape, y_train.shape, y_trainOut.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of cancel in train set without outliers 0.2804503582395087\n"
     ]
    }
   ],
   "source": [
    "# Count the number of canceled bookings in the training (without outlier s) set and calculate the percentage\n",
    "NOcanceled =y_trainOut.sum()\n",
    "total=y_trainOut.shape[0]\n",
    "print('Percentage of cancel in train set without outliers',NOcanceled/total)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can observe that the percentage of cancellations has decreased after removing the outliers. This was expected to have a negative impact on the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scaling\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the MinMaxScaler class\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the training data using fit_transform()\n",
    "X_trainOut = scaler.fit_transform(X_trainOut)\n",
    "\n",
    "# Scale the test data using transform()\n",
    "X_testOut = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the MinMaxScaler class\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the training data using fit_transform()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Scale the test data using transform()\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now proceed to build different models for both datasets, one with outliers and one without outliers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.8069208099629243\n",
      "test accuracy: 0.8006843455945253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OMARS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the LogisticRegression class\n",
    "log=LogisticRegression()\n",
    "\n",
    "# Fit the logistic regression model to the training data using the fit() method\n",
    "log.fit(X_train,y_train)\n",
    "\n",
    "# Use the predict() method of the logistic regression model to predict the classes of the training data\n",
    "yd=log.predict(X_train)\n",
    "\n",
    "# Compute the accuracy of the model on the training data using the accuracy_score() function\n",
    "print('train accuracy:',accuracy_score(yd,y_train))\n",
    "\n",
    "# Compute the accuracy of the model on the test data using the accuracy_score() function\n",
    "yed=log.predict(X_test)\n",
    "print('test accuracy:',accuracy_score(yed,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.8056294779938588\n",
      "test accuracy: 0.7966923296264614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OMARS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the LogisticRegression class\n",
    "log=LogisticRegression()\n",
    "\n",
    "# Fit the logistic regression model to the training data using the fit() method\n",
    "log.fit(X_trainOut,y_trainOut)\n",
    "\n",
    "# Use the predict() method of the logistic regression model to predict the classes of the training data\n",
    "yd=log.predict(X_trainOut)\n",
    "\n",
    "# Compute the accuracy of the model on the training data using the accuracy_score() function\n",
    "print('train accuracy:',accuracy_score(yd,y_trainOut))\n",
    "\n",
    "# Compute the accuracy of the model on the test data using the accuracy_score() function\n",
    "yed=log.predict(X_testOut)\n",
    "print('test accuracy:',accuracy_score(yed,y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': 16}\n",
      "Accuracy on testing data:  0.8494439692044482\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the RandomForestClassifier class with 100 decision trees\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Define a dictionary of hyperparameters to tune\n",
    "param_grid = {'max_depth': range(1, 31)}\n",
    "\n",
    "# Create a GridSearchCV object with the random forest classifier, hyperparameter grid, and 10-fold cross-validation\n",
    "grid_search = GridSearchCV(rfc, param_grid=param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best set of hyperparameters found by the grid search.\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the accuracy of the model on the testing data using the best set of hyperparameters found by the grid search.\n",
    "print(\"Accuracy on testing data: \", grid_search.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9163418575910257\n",
      "Test accuracy: 0.8542914171656687\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the RandomForestClassifier class with 300 decision trees and a maximum depth of 15\n",
    "rfc = RandomForestClassifier(n_estimators=300, max_depth=16)\n",
    "\n",
    "# Fit the random forest classifier to the training data using the fit() method\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Use the predict() method of the random forest classifier to predict the classes of the training data\n",
    "y_pred = rfc.predict(X_train)\n",
    "\n",
    "# Compute the accuracy of the model on the training data using the accuracy_score() function\n",
    "train_acc = accuracy_score(y_train, y_pred)\n",
    "print('Train accuracy:', train_acc)\n",
    "\n",
    "# Use the predict() method of the random forest classifier to predict the classes of the test data\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the model on the test data using the accuracy_score() function\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': 15}\n",
      "Accuracy on testing data:  0.846307385229541\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the RandomForestClassifier class with 100 decision trees\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Define a dictionary of hyperparameters to tune\n",
    "param_grid = {'max_depth': range(1, 31)}\n",
    "\n",
    "# Create a GridSearchCV object with the random forest classifier, hyperparameter grid, and 10-fold cross-validation\n",
    "grid_search = GridSearchCV(rfc, param_grid=param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_trainOut, y_trainOut)\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Print the accuracy of the model on the test data using the best hyperparameters found by GridSearchCV\n",
    "print(\"Accuracy on testing data: \", grid_search.score(X_testOut, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9165813715455476\n",
      "test accuracy: 0.8488736812090105\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the RandomForestClassifier class with 300 decision trees and a maximum depth of 15\n",
    "rfc = RandomForestClassifier(n_estimators=300, max_depth=16)\n",
    "\n",
    "# Fit the random forest classifier to the training data\n",
    "rfc.fit(X_trainOut, y_trainOut)\n",
    "\n",
    "# Use the fitted model to make predictions on the training data and print the accuracy\n",
    "y_pred = rfc.predict(X_trainOut)\n",
    "print('train accuracy:', accuracy_score(y_trainOut, y_pred))\n",
    "\n",
    "# Use the fitted model to make predictions on the test data and print the accuracy\n",
    "y_pred = rfc.predict(X_testOut)\n",
    "print('test accuracy:', accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighbors Classifier\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of n_neighbors: {'n_neighbors': 9}\n",
      "Accuracy of KNN classifier with best n_neighbors: 0.799258625605931\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the KNeighborsClassifier class\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Set the range of hyperparameter values to test for the number of neighbors, and use 10-fold cross validation\n",
    "param_grid = {'n_neighbors': range(1, 11)}\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best value of n_neighbors found by the grid search\n",
    "print(\"Best value of n_neighbors:\", grid_search.best_params_)\n",
    "\n",
    "# Calculate the accuracy of the KNN classifier using the best value of n_neighbors found by the grid search\n",
    "accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Accuracy of KNN classifier with best n_neighbors:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.8342998383876794\n",
      "test accuracy: 0.799258625605931\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the KNeighborsClassifier class with n_neighbors=9\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "# Fit the KNN model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training data and calculate the accuracy\n",
    "y_pred = knn.predict(X_train)\n",
    "print('train accuracy:' ,accuracy_score(y_train, y_pred))\n",
    "\n",
    "# Make predictions on the testing data and calculate the accuracy\n",
    "y_pred = knn.predict(X_test)\n",
    "print('test accuracy:' ,accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of n_neighbors: {'n_neighbors': 9}\n",
      "Accuracy of KNN classifier with best n_neighbors: 0.7909894496720844\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the KNeighborsClassifier class\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define a dictionary of parameter values to be searched over\n",
    "param_grid = {'n_neighbors': range(1, 11)}\n",
    "\n",
    "# Create an instance of GridSearchCV with 10-fold cross-validation and 'accuracy' as the scoring metric\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_trainOut, y_trainOut)\n",
    "\n",
    "# Print the best value of n_neighbors found during the grid search\n",
    "print(\"Best value of n_neighbors:\", grid_search.best_params_)\n",
    "\n",
    "# Calculate the accuracy of the best KNN classifier on the testing data\n",
    "accuracy = grid_search.score(X_testOut, y_test)\n",
    "print(\"Accuracy of KNN classifier with best n_neighbors:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.8425793244626407\n",
      "test accuracy: 0.7909894496720844\n"
     ]
    }
   ],
   "source": [
    "# Import the KNeighborsClassifier class from scikit-learn library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create an instance of the KNeighborsClassifier class with n_neighbors=9\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "# Fit the KNN classifier to the training data\n",
    "knn.fit(X_trainOut, y_trainOut)\n",
    "\n",
    "# Use the KNN classifier to make predictions on the training data and calculate the accuracy\n",
    "y_pred = knn.predict(X_trainOut)\n",
    "print('train accuracy:' ,accuracy_score(y_trainOut, y_pred))\n",
    "\n",
    "# Use the KNN classifier to make predictions on the testing data and calculate the accuracy\n",
    "y_pred = knn.predict(X_testOut)\n",
    "print('test accuracy:' ,accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (poly)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'degree': 8, 'kernel': 'poly'}\n",
      "train accuracy: 0.8505561365148778\n",
      "test accuracy: 0.8177929854576561\n"
     ]
    }
   ],
   "source": [
    "# define the parameters to search over\n",
    "parameters = {'kernel':['poly'], 'degree':range(2,11)}\n",
    "\n",
    "# initialize the SVM classifier\n",
    "svmc = SVC()\n",
    "\n",
    "# perform a grid search with 10-fold cross-validation and accuracy scoring\n",
    "clf = GridSearchCV(svmc, parameters, cv=10, scoring='accuracy')\n",
    "\n",
    "# fit the model to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# print the best parameters found by the grid search\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "\n",
    "# predict the labels of the training data and compute the accuracy\n",
    "y_pred = clf.predict(X_train)\n",
    "print('train accuracy:', accuracy_score(y_train, y_pred))\n",
    "\n",
    "# predict the labels of the testing data and compute the accuracy\n",
    "y_pred = clf.predict(X_test)\n",
    "print('test accuracy:', accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'degree': 9, 'kernel': 'poly'}\n",
      "train accuracy: 0.8623336745138178\n",
      "test accuracy: 0.8177929854576561\n"
     ]
    }
   ],
   "source": [
    "# define the parameters to search over\n",
    "parameters = {'kernel':['poly'], 'degree':range(2,11)}\n",
    "\n",
    "# initialize the SVM classifier\n",
    "svmc = SVC()\n",
    "\n",
    "# perform a grid search with 10-fold cross-validation and accuracy scoring\n",
    "clf = GridSearchCV(svmc, parameters, cv=10, scoring='accuracy')\n",
    "\n",
    "# fit the model to the training data\n",
    "clf.fit(X_trainOut, y_trainOut)\n",
    "\n",
    "# print the best parameters found by the grid search\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "\n",
    "# predict the labels of the training data and compute the accuracy\n",
    "y_pred = clf.predict(X_trainOut)\n",
    "print('train accuracy:', accuracy_score(y_trainOut, y_pred))\n",
    "\n",
    "# predict the labels of the testing data and compute the accuracy\n",
    "y_pred = clf.predict(X_testOut)\n",
    "print('test accuracy:', accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 6, 'max_features': 9}\n",
      "Accuracy of Gradient Boosting Classifier with best parameters: 0.8545765611633875\n"
     ]
    }
   ],
   "source": [
    "# Initialize Gradient Boosting Classifier with 100 estimators and a random state of 40\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=40)\n",
    "\n",
    "# Define the grid of hyperparameters to search over\n",
    "param_grid = {'learning_rate': [0.1], 'max_depth': range(2, 10), 'max_features': range(4, 12)}\n",
    "\n",
    "# Perform grid search using 5-fold cross validation and accuracy as the scoring metric\n",
    "grid_search = GridSearchCV(gb_clf, param_grid, cv=5, scoring='accuracy', verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by the grid search\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Calculate and print the accuracy of the model on the testing data using the best hyperparameters found by the grid search\n",
    "accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Accuracy of Gradient Boosting Classifier with best parameters:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9360205342713186\n",
      "test accuracy: 0.8545765611633875\n"
     ]
    }
   ],
   "source": [
    "# Create a Gradient Boosting Classifier with specified hyperparameters\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=300, learning_rate=0.1, max_features=9, max_depth=6, random_state=40)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training data and calculate the accuracy\n",
    "y_pred = gb_clf.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('train accuracy:' ,accuracy) \n",
    "\n",
    "# Make predictions on the test data and calculate the accuracy\n",
    "y_pred = gb_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('test accuracy:' ,accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 7, 'max_features': 11}\n",
      "Accuracy of Gradient Boosting Classifier with best parameters: 0.8485885372112917\n"
     ]
    }
   ],
   "source": [
    "# Create a Gradient Boosting Classifier object with 100 estimators\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=40)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {'learning_rate': [0.1],'max_depth':range(2, 10), 'max_features':range(4, 12)}\n",
    "\n",
    "# Perform a grid search using 5-fold cross-validation\n",
    "grid_search = GridSearchCV(gb_clf, param_grid, cv=5, scoring='accuracy', verbose=0)\n",
    "\n",
    "# Fit the grid search object on the oversampled training data\n",
    "grid_search.fit(X_trainOut, y_trainOut)\n",
    "\n",
    "# Print the best parameters found by the grid search\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Calculate the accuracy of the Gradient Boosting Classifier on the oversampled testing data using the best parameters\n",
    "accuracy = grid_search.score(X_testOut, y_test)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy of Gradient Boosting Classifier with best parameters:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9471852610030707\n",
      "test accuracy: 0.8448816652409467\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the GradientBoostingClassifier model with the specified hyperparameters\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=300, learning_rate=0.1, max_features=11, max_depth=6, random_state=40)\n",
    "\n",
    "# Fit the model to the training data\n",
    "gb_clf.fit(X_trainOut, y_trainOut)\n",
    "\n",
    "# Use the trained model to predict the target variable of the training data\n",
    "y_pred = gb_clf.predict(X_trainOut)\n",
    "\n",
    "# Calculate the accuracy of the model on the training data\n",
    "accuracy = accuracy_score(y_trainOut, y_pred)\n",
    "\n",
    "# Print the accuracy of the model on the training data\n",
    "print('train accuracy:', accuracy) \n",
    "\n",
    "# Use the trained model to predict the target variable of the testing data\n",
    "y_pred = gb_clf.predict(X_testOut)\n",
    "\n",
    "# Calculate the accuracy of the model on the testing data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy of the model on the testing data\n",
    "print('test accuracy:', accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the previous models, it was found that the dataset with outliers produced better results than the dataset without outliers. As we anticipated, going forward, we will be using only the dataset with outliers for the purpose of project time scope."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into a partial training set and a validation set\n",
    "partial_X_train , X_val, partial_y_train , y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "model = models.Sequential([\n",
    "  layers.Dense(64, activation='relu', input_dim=partial_X_train.shape[1]),\n",
    "  layers.Dense(32, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with the rmsprop optimizer, binary crossentropy loss function, and accuracy metric\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set up early stopping based on validation accuracy with a patience of 30 epochs\n",
    "es = EarlyStopping(monitor='val_accuracy', patience=30, mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the training data and validation data\n",
    "history = model.fit(partial_X_train, partial_y_train, epochs=1000, batch_size=512, verbose=0,callbacks=[es], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 813us/step\n",
      "Test Accuracy: 0.812375249500998\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the trained model on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the probabilities to binary predictions using a threshold of 0.5\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate the accuracy on the test data\n",
    "accuracy = (y_pred_binary[:,0] == y_test).mean()\n",
    "\n",
    "# Print the test accuracy\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has been determined that the top three models are the GradientBoostingClassifier, RandomForestClassifier, and Support Vector Machine. To create the final model, we will be using a Voting Classifier that combines these three models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model :Voting Classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.86977186 0.85646388 0.85741445 0.84220532 0.84885932 0.84505703\n",
      " 0.84220532 0.85171103 0.84695817 0.84205519]\n",
      "Mean cross-validation score: 0.8502701573370283\n",
      "train accuracy: 0.902272079094971\n",
      "Test accuracy: 0.8554319931565441\n"
     ]
    }
   ],
   "source": [
    "clf1 = GradientBoostingClassifier(n_estimators=300, learning_rate=0.1, max_features=9, max_depth=6, random_state=40)\n",
    "clf2 = RandomForestClassifier(n_estimators=300,max_depth=14)\n",
    "clf3 = SVC(kernel='poly',degree=8, probability=True)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('gb', clf1), ('rf', clf2),('sv',clf3)], voting='soft')\n",
    "\n",
    "cv_scores = cross_val_score(voting_clf, X_train, y_train, cv=10)\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(\"train accuracy:\", accuracy)\n",
    "\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
